{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec5ee81",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc9eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab055f",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90e8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'metal', 'paper', 'plastic']\n",
      "Train size: 36276\n",
      "Validation size: 9070\n",
      "Train class counts: Counter({np.int64(1): 12689, np.int64(3): 8522, np.int64(4): 4450, np.int64(6): 2632, np.int64(7): 2421, np.int64(2): 2303, np.int64(5): 1748, np.int64(0): 1511})\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"dataset\"\n",
    "train_ratio = 0.8\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=root_dir)\n",
    "targets = np.array(full_dataset.targets)\n",
    "indices = np.arange(len(targets))\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=1 - train_ratio,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(datasets.ImageFolder(root=root_dir, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(datasets.ImageFolder(root=root_dir, transform=val_transform), val_idx)\n",
    "\n",
    "train_targets = targets[train_idx]\n",
    "class_counts = Counter(train_targets)\n",
    "num_samples = len(train_dataset)\n",
    "\n",
    "class_weights = {cls: num_samples / count for cls, count in class_counts.items()}\n",
    "sample_weights = [class_weights[t] for t in train_targets]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    sampler=sampler,\n",
    "    num_workers=num_workers)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "print(\"Classes:\", full_dataset.classes)\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(val_dataset))\n",
    "print(\"Train class counts:\", class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb64b04",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69be00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f166da",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436e75d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912e6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.3508 | Train Acc: 0.8825 | Val Loss: 0.1896 | Val Acc: 0.9405 | F1 (macro): 0.9184\n",
      "Epoch [2/10] Train Loss: 0.2826 | Train Acc: 0.9051 | Val Loss: 0.1839 | Val Acc: 0.9444 | F1 (macro): 0.9253\n",
      "Epoch [3/10] Train Loss: 0.2425 | Train Acc: 0.9200 | Val Loss: 0.1483 | Val Acc: 0.9549 | F1 (macro): 0.9408\n",
      "Epoch [4/10] Train Loss: 0.2150 | Train Acc: 0.9285 | Val Loss: 0.1406 | Val Acc: 0.9551 | F1 (macro): 0.9396\n",
      "Epoch [5/10] Train Loss: 0.1964 | Train Acc: 0.9337 | Val Loss: 0.1090 | Val Acc: 0.9656 | F1 (macro): 0.9509\n",
      "Epoch [6/10] Train Loss: 0.1898 | Train Acc: 0.9370 | Val Loss: 0.1201 | Val Acc: 0.9643 | F1 (macro): 0.9512\n",
      "Epoch [7/10] Train Loss: 0.1753 | Train Acc: 0.9410 | Val Loss: 0.1420 | Val Acc: 0.9526 | F1 (macro): 0.9408\n",
      "Epoch [8/10] Train Loss: 0.1737 | Train Acc: 0.9422 | Val Loss: 0.1035 | Val Acc: 0.9685 | F1 (macro): 0.9593\n",
      "Epoch [9/10] Train Loss: 0.1610 | Train Acc: 0.9463 | Val Loss: 0.0975 | Val Acc: 0.9691 | F1 (macro): 0.9562\n",
      "Epoch [10/10] Train Loss: 0.1541 | Train Acc: 0.9482 | Val Loss: 0.1089 | Val Acc: 0.9687 | F1 (macro): 0.9565\n",
      "\n",
      "Final classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.89      0.99      0.94       378\n",
      "  biological       1.00      0.95      0.97      3173\n",
      "   cardboard       0.92      0.97      0.94       576\n",
      "     clothes       0.99      1.00      0.99      2130\n",
      "       glass       0.95      0.97      0.96      1113\n",
      "       metal       0.95      0.92      0.94       437\n",
      "       paper       0.96      0.98      0.97       658\n",
      "     plastic       0.92      0.96      0.94       605\n",
      "\n",
      "    accuracy                           0.97      9070\n",
      "   macro avg       0.95      0.97      0.96      9070\n",
      "weighted avg       0.97      0.97      0.97      9070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "        f\"F1 (macro): {f1_macro:.4f}\")\n",
    "\n",
    "print(\"\\nFinal classification report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=full_dataset.classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e40d0b",
   "metadata": {},
   "source": [
    "# Exporting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a6ceb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa4aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1103 22:39:45.899000 17240 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
      "Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 40 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 18},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu126',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,3,224,224]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,8]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"fc.bias\"<FLOAT,[8]>{TorchTensor<FLOAT,[8]>(Parameter containing: tensor([ 0.0259,  0.0412,  0.0469, -0.0120,  0.0289,  0.0023, -0.0309, -0.0034], device='cuda:0', requires_grad=True), name='fc.bias')},\n",
       "                %\"conv1.weight\"<FLOAT,[64,3,7,7]>{Tensor(...)},\n",
       "                %\"layer1.0.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer1.0.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer1.1.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer1.1.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer2.0.conv1.weight\"<FLOAT,[128,64,3,3]>{Tensor(...)},\n",
       "                %\"layer2.0.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"layer2.0.downsample.0.weight\"<FLOAT,[128,64,1,1]>{Tensor(...)},\n",
       "                %\"layer2.1.conv1.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"layer2.1.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"layer3.0.conv1.weight\"<FLOAT,[256,128,3,3]>{Tensor(...)},\n",
       "                %\"layer3.0.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"layer3.0.downsample.0.weight\"<FLOAT,[256,128,1,1]>{Tensor(...)},\n",
       "                %\"layer3.1.conv1.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"layer3.1.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"layer4.0.conv1.weight\"<FLOAT,[512,256,3,3]>{Tensor(...)},\n",
       "                %\"layer4.0.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"layer4.0.downsample.0.weight\"<FLOAT,[512,256,1,1]>{Tensor(...)},\n",
       "                %\"layer4.1.conv1.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"layer4.1.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"fc.weight\"<FLOAT,[8,512]>{TorchTensor(...)},\n",
       "                %\"val_186\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_186')},\n",
       "                %\"val_190\"<INT64,[2]>{Tensor<INT64,[2]>(array([  1, 512]), name='val_190')},\n",
       "                %\"input_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"max_pool2d_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_1_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_2_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_3_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_4_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_5_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_6_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_7_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_8_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_9_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_10_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_11_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_12_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_13_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_14_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_15_bias\"<FLOAT,[512]>{Tensor(...)}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Conv_251\n",
       "                  %\"getitem\"<FLOAT,[1,64,112,112]> ⬅️ ::Conv(%\"input\", %\"conv1.weight\"{...}, %\"input_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(3, 3, 3, 3)}\n",
       "             1 |  # node_relu\n",
       "                  %\"relu\"<FLOAT,[1,64,112,112]> ⬅️ ::Relu(%\"getitem\")\n",
       "             2 |  # node_max_pool2d\n",
       "                  %\"max_pool2d\"<FLOAT,[1,64,56,56]>, %\"\"<?,?> ⬅️ ::MaxPool(%\"relu\") {kernel_shape=(3, 3), strides=(2, 2), dilations=(1, 1), auto_pad='NOTSET', pads=(1, 1, 1, 1), ceil_mode=0, storage_order=0}\n",
       "             3 |  # node_Conv_253\n",
       "                  %\"getitem_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"max_pool2d\", %\"layer1.0.conv1.weight\"{...}, %\"max_pool2d_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             4 |  # node_relu_1\n",
       "                  %\"relu_1\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_3\")\n",
       "             5 |  # node_Conv_255\n",
       "                  %\"getitem_6\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_1\", %\"layer1.0.conv2.weight\"{...}, %\"relu_1_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             6 |  # node_add\n",
       "                  %\"add\"<FLOAT,[1,64,56,56]> ⬅️ ::Add(%\"getitem_6\", %\"max_pool2d\")\n",
       "             7 |  # node_relu_2\n",
       "                  %\"relu_2\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"add\")\n",
       "             8 |  # node_Conv_257\n",
       "                  %\"getitem_9\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_2\", %\"layer1.1.conv1.weight\"{...}, %\"relu_2_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             9 |  # node_relu_3\n",
       "                  %\"relu_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_9\")\n",
       "            10 |  # node_Conv_259\n",
       "                  %\"getitem_12\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_3\", %\"layer1.1.conv2.weight\"{...}, %\"relu_3_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            11 |  # node_add_1\n",
       "                  %\"add_1\"<FLOAT,[1,64,56,56]> ⬅️ ::Add(%\"getitem_12\", %\"relu_2\")\n",
       "            12 |  # node_relu_4\n",
       "                  %\"relu_4\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"add_1\")\n",
       "            13 |  # node_Conv_261\n",
       "                  %\"getitem_15\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_4\", %\"layer2.0.conv1.weight\"{...}, %\"relu_4_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            14 |  # node_relu_5\n",
       "                  %\"relu_5\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_15\")\n",
       "            15 |  # node_Conv_263\n",
       "                  %\"getitem_18\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_5\", %\"layer2.0.conv2.weight\"{...}, %\"relu_5_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            16 |  # node_Conv_265\n",
       "                  %\"getitem_21\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_4\", %\"layer2.0.downsample.0.weight\"{...}, %\"relu_4_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            17 |  # node_add_2\n",
       "                  %\"add_2\"<FLOAT,[1,128,28,28]> ⬅️ ::Add(%\"getitem_18\", %\"getitem_21\")\n",
       "            18 |  # node_relu_6\n",
       "                  %\"relu_6\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"add_2\")\n",
       "            19 |  # node_Conv_267\n",
       "                  %\"getitem_24\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_6\", %\"layer2.1.conv1.weight\"{...}, %\"relu_6_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            20 |  # node_relu_7\n",
       "                  %\"relu_7\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_24\")\n",
       "            21 |  # node_Conv_269\n",
       "                  %\"getitem_27\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_7\", %\"layer2.1.conv2.weight\"{...}, %\"relu_7_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            22 |  # node_add_3\n",
       "                  %\"add_3\"<FLOAT,[1,128,28,28]> ⬅️ ::Add(%\"getitem_27\", %\"relu_6\")\n",
       "            23 |  # node_relu_8\n",
       "                  %\"relu_8\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"add_3\")\n",
       "            24 |  # node_Conv_271\n",
       "                  %\"getitem_30\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_8\", %\"layer3.0.conv1.weight\"{...}, %\"relu_8_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            25 |  # node_relu_9\n",
       "                  %\"relu_9\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_30\")\n",
       "            26 |  # node_Conv_273\n",
       "                  %\"getitem_33\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_9\", %\"layer3.0.conv2.weight\"{...}, %\"relu_9_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            27 |  # node_Conv_275\n",
       "                  %\"getitem_36\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_8\", %\"layer3.0.downsample.0.weight\"{...}, %\"relu_8_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            28 |  # node_add_4\n",
       "                  %\"add_4\"<FLOAT,[1,256,14,14]> ⬅️ ::Add(%\"getitem_33\", %\"getitem_36\")\n",
       "            29 |  # node_relu_10\n",
       "                  %\"relu_10\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"add_4\")\n",
       "            30 |  # node_Conv_277\n",
       "                  %\"getitem_39\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_10\", %\"layer3.1.conv1.weight\"{...}, %\"relu_10_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            31 |  # node_relu_11\n",
       "                  %\"relu_11\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_39\")\n",
       "            32 |  # node_Conv_279\n",
       "                  %\"getitem_42\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_11\", %\"layer3.1.conv2.weight\"{...}, %\"relu_11_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            33 |  # node_add_5\n",
       "                  %\"add_5\"<FLOAT,[1,256,14,14]> ⬅️ ::Add(%\"getitem_42\", %\"relu_10\")\n",
       "            34 |  # node_relu_12\n",
       "                  %\"relu_12\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"add_5\")\n",
       "            35 |  # node_Conv_281\n",
       "                  %\"getitem_45\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_12\", %\"layer4.0.conv1.weight\"{...}, %\"relu_12_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            36 |  # node_relu_13\n",
       "                  %\"relu_13\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_45\")\n",
       "            37 |  # node_Conv_283\n",
       "                  %\"getitem_48\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_13\", %\"layer4.0.conv2.weight\"{...}, %\"relu_13_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            38 |  # node_Conv_285\n",
       "                  %\"getitem_51\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_12\", %\"layer4.0.downsample.0.weight\"{...}, %\"relu_12_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            39 |  # node_add_6\n",
       "                  %\"add_6\"<FLOAT,[1,512,7,7]> ⬅️ ::Add(%\"getitem_48\", %\"getitem_51\")\n",
       "            40 |  # node_relu_14\n",
       "                  %\"relu_14\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"add_6\")\n",
       "            41 |  # node_Conv_287\n",
       "                  %\"getitem_54\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_14\", %\"layer4.1.conv1.weight\"{...}, %\"relu_14_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            42 |  # node_relu_15\n",
       "                  %\"relu_15\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_54\")\n",
       "            43 |  # node_Conv_289\n",
       "                  %\"getitem_57\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_15\", %\"layer4.1.conv2.weight\"{...}, %\"relu_15_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            44 |  # node_add_7\n",
       "                  %\"add_7\"<FLOAT,[1,512,7,7]> ⬅️ ::Add(%\"getitem_57\", %\"relu_14\")\n",
       "            45 |  # node_relu_16\n",
       "                  %\"relu_16\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"add_7\")\n",
       "            46 |  # node_mean\n",
       "                  %\"mean\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"relu_16\", %\"val_186\"{[-1, -2]}) {keepdims=1, noop_with_empty_axes=0}\n",
       "            47 |  # node_view\n",
       "                  %\"view\"<FLOAT,[1,512]> ⬅️ ::Reshape(%\"mean\", %\"val_190\"{[1, 512]}) {allowzero=1}\n",
       "            48 |  # node_linear\n",
       "                  %\"output\"<FLOAT,[1,8]> ⬅️ ::Gemm(%\"view\", %\"fc.weight\"{...}, %\"fc.bias\"{[0.02589268796145916, 0.04117332026362419, 0.046851325780153275, -0.01200625579804182, 0.02888130582869053, 0.0022712594363838434, -0.030923938378691673, -0.003445676062256098]}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            return %\"output\"<FLOAT,[1,8]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_conv1_weight: \"f32[64, 3, 7, 7]\", p_bn1_weight: \"f32[64]\", p_bn1_bias: \"f32[64]\", p_layer1_0_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn1_weight: \"f32[64]\", p_layer1_0_bn1_bias: \"f32[64]\", p_layer1_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn2_weight: \"f32[64]\", p_layer1_0_bn2_bias: \"f32[64]\", p_layer1_1_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn1_weight: \"f32[64]\", p_layer1_1_bn1_bias: \"f32[64]\", p_layer1_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn2_weight: \"f32[64]\", p_layer1_1_bn2_bias: \"f32[64]\", p_layer2_0_conv1_weight: \"f32[128, 64, 3, 3]\", p_layer2_0_bn1_weight: \"f32[128]\", p_layer2_0_bn1_bias: \"f32[128]\", p_layer2_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_0_bn2_weight: \"f32[128]\", p_layer2_0_bn2_bias: \"f32[128]\", p_layer2_0_downsample_0_weight: \"f32[128, 64, 1, 1]\", p_layer2_0_downsample_1_weight: \"f32[128]\", p_layer2_0_downsample_1_bias: \"f32[128]\", p_layer2_1_conv1_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn1_weight: \"f32[128]\", p_layer2_1_bn1_bias: \"f32[128]\", p_layer2_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn2_weight: \"f32[128]\", p_layer2_1_bn2_bias: \"f32[128]\", p_layer3_0_conv1_weight: \"f32[256, 128, 3, 3]\", p_layer3_0_bn1_weight: \"f32[256]\", p_layer3_0_bn1_bias: \"f32[256]\", p_layer3_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_0_bn2_weight: \"f32[256]\", p_layer3_0_bn2_bias: \"f32[256]\", p_layer3_0_downsample_0_weight: \"f32[256, 128, 1, 1]\", p_layer3_0_downsample_1_weight: \"f32[256]\", p_layer3_0_downsample_1_bias: \"f32[256]\", p_layer3_1_conv1_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn1_weight: \"f32[256]\", p_layer3_1_bn1_bias: \"f32[256]\", p_layer3_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn2_weight: \"f32[256]\", p_layer3_1_bn2_bias: \"f32[256]\", p_layer4_0_conv1_weight: \"f32[512, 256, 3, 3]\", p_layer4_0_bn1_weight: \"f32[512]\", p_layer4_0_bn1_bias: \"f32[512]\", p_layer4_0_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_0_bn2_weight: \"f32[512]\", p_layer4_0_bn2_bias: \"f32[512]\", p_layer4_0_downsample_0_weight: \"f32[512, 256, 1, 1]\", p_layer4_0_downsample_1_weight: \"f32[512]\", p_layer4_0_downsample_1_bias: \"f32[512]\", p_layer4_1_conv1_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn1_weight: \"f32[512]\", p_layer4_1_bn1_bias: \"f32[512]\", p_layer4_1_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn2_weight: \"f32[512]\", p_layer4_1_bn2_bias: \"f32[512]\", p_fc_weight: \"f32[8, 512]\", p_fc_bias: \"f32[8]\", b_bn1_running_mean: \"f32[64]\", b_bn1_running_var: \"f32[64]\", b_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn1_running_mean: \"f32[64]\", b_layer1_0_bn1_running_var: \"f32[64]\", b_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn2_running_mean: \"f32[64]\", b_layer1_0_bn2_running_var: \"f32[64]\", b_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_layer1_1_bn1_running_mean: \"f32[64]\", b_layer1_1_bn1_running_var: \"f32[64]\", b_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_layer1_1_bn2_running_mean: \"f32[64]\", b_layer1_1_bn2_running_var: \"f32[64]\", b_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_bn1_running_mean: \"f32[128]\", b_layer2_0_bn1_running_var: \"f32[128]\", b_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_layer2_0_bn2_running_mean: \"f32[128]\", b_layer2_0_bn2_running_var: \"f32[128]\", b_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_downsample_1_running_mean: \"f32[128]\", b_layer2_0_downsample_1_running_var: \"f32[128]\", b_layer2_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer2_1_bn1_running_mean: \"f32[128]\", b_layer2_1_bn1_running_var: \"f32[128]\", b_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_layer2_1_bn2_running_mean: \"f32[128]\", b_layer2_1_bn2_running_var: \"f32[128]\", b_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_bn1_running_mean: \"f32[256]\", b_layer3_0_bn1_running_var: \"f32[256]\", b_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_layer3_0_bn2_running_mean: \"f32[256]\", b_layer3_0_bn2_running_var: \"f32[256]\", b_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_downsample_1_running_mean: \"f32[256]\", b_layer3_0_downsample_1_running_var: \"f32[256]\", b_layer3_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer3_1_bn1_running_mean: \"f32[256]\", b_layer3_1_bn1_running_var: \"f32[256]\", b_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_layer3_1_bn2_running_mean: \"f32[256]\", b_layer3_1_bn2_running_var: \"f32[256]\", b_layer3_1_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_bn1_running_mean: \"f32[512]\", b_layer4_0_bn1_running_var: \"f32[512]\", b_layer4_0_bn1_num_batches_tracked: \"i64[]\", b_layer4_0_bn2_running_mean: \"f32[512]\", b_layer4_0_bn2_running_var: \"f32[512]\", b_layer4_0_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_downsample_1_running_mean: \"f32[512]\", b_layer4_0_downsample_1_running_var: \"f32[512]\", b_layer4_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer4_1_bn1_running_mean: \"f32[512]\", b_layer4_1_bn1_running_var: \"f32[512]\", b_layer4_1_bn1_num_batches_tracked: \"i64[]\", b_layer4_1_bn2_running_mean: \"f32[512]\", b_layer4_1_bn2_running_var: \"f32[512]\", b_layer4_1_bn2_num_batches_tracked: \"i64[]\", x: \"f32[1, 3, 224, 224]\"):\n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[1, 64, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_conv1_weight, None, [2, 2], [3, 3]);  x = p_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_bn1_weight, p_bn1_bias, b_bn1_running_mean, b_bn1_running_var, 0.1, 1e-05);  conv2d = p_bn1_weight = p_bn1_bias = b_bn1_running_mean = b_bn1_running_var = None\n",
       "                    getitem: \"f32[1, 64, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[1, 64, 112, 112]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:226 in forward, code: return F.max_pool2d(\n",
       "                    max_pool2d: \"f32[1, 64, 56, 56]\" = torch.ops.aten.max_pool2d.default(relu, [3, 3], [2, 2], [1, 1]);  relu = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_layer1_0_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_layer1_0_bn1_weight, p_layer1_0_bn1_bias, b_layer1_0_bn1_running_mean, b_layer1_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_layer1_0_bn1_weight = p_layer1_0_bn1_bias = b_layer1_0_bn1_running_mean = b_layer1_0_bn1_running_var = None\n",
       "                    getitem_3: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_1, p_layer1_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_layer1_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_layer1_0_bn2_weight, p_layer1_0_bn2_bias, b_layer1_0_bn2_running_mean, b_layer1_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_layer1_0_bn2_weight = p_layer1_0_bn2_bias = b_layer1_0_bn2_running_mean = b_layer1_0_bn2_running_var = None\n",
       "                    getitem_6: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add: \"f32[1, 64, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_6, max_pool2d);  getitem_6 = max_pool2d = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(add);  add = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_2, p_layer1_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_layer1_1_bn1_weight, p_layer1_1_bn1_bias, b_layer1_1_bn1_running_mean, b_layer1_1_bn1_running_var, 0.1, 1e-05);  conv2d_3 = p_layer1_1_bn1_weight = p_layer1_1_bn1_bias = b_layer1_1_bn1_running_mean = b_layer1_1_bn1_running_var = None\n",
       "                    getitem_9: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_3: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_3, p_layer1_1_conv2_weight, None, [1, 1], [1, 1]);  relu_3 = p_layer1_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_layer1_1_bn2_weight, p_layer1_1_bn2_bias, b_layer1_1_bn2_running_mean, b_layer1_1_bn2_running_var, 0.1, 1e-05);  conv2d_4 = p_layer1_1_bn2_weight = p_layer1_1_bn2_bias = b_layer1_1_bn2_running_mean = b_layer1_1_bn2_running_var = None\n",
       "                    getitem_12: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_12, relu_2);  getitem_12 = relu_2 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(add_1);  add_1 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_4, p_layer2_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer2_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_layer2_0_bn1_weight, p_layer2_0_bn1_bias, b_layer2_0_bn1_running_mean, b_layer2_0_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_layer2_0_bn1_weight = p_layer2_0_bn1_bias = b_layer2_0_bn1_running_mean = b_layer2_0_bn1_running_var = None\n",
       "                    getitem_15: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_5: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_5, p_layer2_0_conv2_weight, None, [1, 1], [1, 1]);  relu_5 = p_layer2_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_layer2_0_bn2_weight, p_layer2_0_bn2_bias, b_layer2_0_bn2_running_mean, b_layer2_0_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_layer2_0_bn2_weight = p_layer2_0_bn2_bias = b_layer2_0_bn2_running_mean = b_layer2_0_bn2_running_var = None\n",
       "                    getitem_18: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_4, p_layer2_0_downsample_0_weight, None, [2, 2]);  relu_4 = p_layer2_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_layer2_0_downsample_1_weight, p_layer2_0_downsample_1_bias, b_layer2_0_downsample_1_running_mean, b_layer2_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_7 = p_layer2_0_downsample_1_weight = p_layer2_0_downsample_1_bias = b_layer2_0_downsample_1_running_mean = b_layer2_0_downsample_1_running_var = None\n",
       "                    getitem_21: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_2: \"f32[1, 128, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_18, getitem_21);  getitem_18 = getitem_21 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_6: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(add_2);  add_2 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_6, p_layer2_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer2_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_layer2_1_bn1_weight, p_layer2_1_bn1_bias, b_layer2_1_bn1_running_mean, b_layer2_1_bn1_running_var, 0.1, 1e-05);  conv2d_8 = p_layer2_1_bn1_weight = p_layer2_1_bn1_bias = b_layer2_1_bn1_running_mean = b_layer2_1_bn1_running_var = None\n",
       "                    getitem_24: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_7, p_layer2_1_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_layer2_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_layer2_1_bn2_weight, p_layer2_1_bn2_bias, b_layer2_1_bn2_running_mean, b_layer2_1_bn2_running_var, 0.1, 1e-05);  conv2d_9 = p_layer2_1_bn2_weight = p_layer2_1_bn2_bias = b_layer2_1_bn2_running_mean = b_layer2_1_bn2_running_var = None\n",
       "                    getitem_27: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_3: \"f32[1, 128, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_27, relu_6);  getitem_27 = relu_6 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(add_3);  add_3 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_8, p_layer3_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer3_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_layer3_0_bn1_weight, p_layer3_0_bn1_bias, b_layer3_0_bn1_running_mean, b_layer3_0_bn1_running_var, 0.1, 1e-05);  conv2d_10 = p_layer3_0_bn1_weight = p_layer3_0_bn1_bias = b_layer3_0_bn1_running_mean = b_layer3_0_bn1_running_var = None\n",
       "                    getitem_30: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_9: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_9, p_layer3_0_conv2_weight, None, [1, 1], [1, 1]);  relu_9 = p_layer3_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_layer3_0_bn2_weight, p_layer3_0_bn2_bias, b_layer3_0_bn2_running_mean, b_layer3_0_bn2_running_var, 0.1, 1e-05);  conv2d_11 = p_layer3_0_bn2_weight = p_layer3_0_bn2_bias = b_layer3_0_bn2_running_mean = b_layer3_0_bn2_running_var = None\n",
       "                    getitem_33: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_8, p_layer3_0_downsample_0_weight, None, [2, 2]);  relu_8 = p_layer3_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_layer3_0_downsample_1_weight, p_layer3_0_downsample_1_bias, b_layer3_0_downsample_1_running_mean, b_layer3_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_12 = p_layer3_0_downsample_1_weight = p_layer3_0_downsample_1_bias = b_layer3_0_downsample_1_running_mean = b_layer3_0_downsample_1_running_var = None\n",
       "                    getitem_36: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_4: \"f32[1, 256, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_33, getitem_36);  getitem_33 = getitem_36 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(add_4);  add_4 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_10, p_layer3_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer3_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_layer3_1_bn1_weight, p_layer3_1_bn1_bias, b_layer3_1_bn1_running_mean, b_layer3_1_bn1_running_var, 0.1, 1e-05);  conv2d_13 = p_layer3_1_bn1_weight = p_layer3_1_bn1_bias = b_layer3_1_bn1_running_mean = b_layer3_1_bn1_running_var = None\n",
       "                    getitem_39: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_11: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_39);  getitem_39 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_11, p_layer3_1_conv2_weight, None, [1, 1], [1, 1]);  relu_11 = p_layer3_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_layer3_1_bn2_weight, p_layer3_1_bn2_bias, b_layer3_1_bn2_running_mean, b_layer3_1_bn2_running_var, 0.1, 1e-05);  conv2d_14 = p_layer3_1_bn2_weight = p_layer3_1_bn2_bias = b_layer3_1_bn2_running_mean = b_layer3_1_bn2_running_var = None\n",
       "                    getitem_42: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_5: \"f32[1, 256, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_42, relu_10);  getitem_42 = relu_10 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(add_5);  add_5 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_15: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_12, p_layer4_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer4_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_layer4_0_bn1_weight, p_layer4_0_bn1_bias, b_layer4_0_bn1_running_mean, b_layer4_0_bn1_running_var, 0.1, 1e-05);  conv2d_15 = p_layer4_0_bn1_weight = p_layer4_0_bn1_bias = b_layer4_0_bn1_running_mean = b_layer4_0_bn1_running_var = None\n",
       "                    getitem_45: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_13: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_16: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_13, p_layer4_0_conv2_weight, None, [1, 1], [1, 1]);  relu_13 = p_layer4_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_layer4_0_bn2_weight, p_layer4_0_bn2_bias, b_layer4_0_bn2_running_mean, b_layer4_0_bn2_running_var, 0.1, 1e-05);  conv2d_16 = p_layer4_0_bn2_weight = p_layer4_0_bn2_bias = b_layer4_0_bn2_running_mean = b_layer4_0_bn2_running_var = None\n",
       "                    getitem_48: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_17: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_12, p_layer4_0_downsample_0_weight, None, [2, 2]);  relu_12 = p_layer4_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_layer4_0_downsample_1_weight, p_layer4_0_downsample_1_bias, b_layer4_0_downsample_1_running_mean, b_layer4_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_17 = p_layer4_0_downsample_1_weight = p_layer4_0_downsample_1_bias = b_layer4_0_downsample_1_running_mean = b_layer4_0_downsample_1_running_var = None\n",
       "                    getitem_51: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_6: \"f32[1, 512, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_48, getitem_51);  getitem_48 = getitem_51 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_14: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(add_6);  add_6 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_18: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_14, p_layer4_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer4_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_layer4_1_bn1_weight, p_layer4_1_bn1_bias, b_layer4_1_bn1_running_mean, b_layer4_1_bn1_running_var, 0.1, 1e-05);  conv2d_18 = p_layer4_1_bn1_weight = p_layer4_1_bn1_bias = b_layer4_1_bn1_running_mean = b_layer4_1_bn1_running_var = None\n",
       "                    getitem_54: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_15: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_19: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_15, p_layer4_1_conv2_weight, None, [1, 1], [1, 1]);  relu_15 = p_layer4_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_layer4_1_bn2_weight, p_layer4_1_bn2_bias, b_layer4_1_bn2_running_mean, b_layer4_1_bn2_running_var, 0.1, 1e-05);  conv2d_19 = p_layer4_1_bn2_weight = p_layer4_1_bn2_bias = b_layer4_1_bn2_running_mean = b_layer4_1_bn2_running_var = None\n",
       "                    getitem_57: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_7: \"f32[1, 512, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_57, relu_14);  getitem_57 = relu_14 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_16: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(add_7);  add_7 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(relu_16, [-1, -2], True);  relu_16 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285 in forward, code: return self._forward_impl(x)\n",
       "                    view: \"f32[1, 512]\" = torch.ops.aten.view.default(mean, [1, 512]);  mean = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 8]\" = torch.ops.aten.linear.default(view, p_fc_weight, p_fc_bias);  view = p_fc_weight = p_fc_bias = None\n",
       "                    return (linear,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_conv1_weight: PARAMETER target='conv1.weight'\n",
       "            p_bn1_weight: PARAMETER target='bn1.weight'\n",
       "            p_bn1_bias: PARAMETER target='bn1.bias'\n",
       "            p_layer1_0_conv1_weight: PARAMETER target='layer1.0.conv1.weight'\n",
       "            p_layer1_0_bn1_weight: PARAMETER target='layer1.0.bn1.weight'\n",
       "            p_layer1_0_bn1_bias: PARAMETER target='layer1.0.bn1.bias'\n",
       "            p_layer1_0_conv2_weight: PARAMETER target='layer1.0.conv2.weight'\n",
       "            p_layer1_0_bn2_weight: PARAMETER target='layer1.0.bn2.weight'\n",
       "            p_layer1_0_bn2_bias: PARAMETER target='layer1.0.bn2.bias'\n",
       "            p_layer1_1_conv1_weight: PARAMETER target='layer1.1.conv1.weight'\n",
       "            p_layer1_1_bn1_weight: PARAMETER target='layer1.1.bn1.weight'\n",
       "            p_layer1_1_bn1_bias: PARAMETER target='layer1.1.bn1.bias'\n",
       "            p_layer1_1_conv2_weight: PARAMETER target='layer1.1.conv2.weight'\n",
       "            p_layer1_1_bn2_weight: PARAMETER target='layer1.1.bn2.weight'\n",
       "            p_layer1_1_bn2_bias: PARAMETER target='layer1.1.bn2.bias'\n",
       "            p_layer2_0_conv1_weight: PARAMETER target='layer2.0.conv1.weight'\n",
       "            p_layer2_0_bn1_weight: PARAMETER target='layer2.0.bn1.weight'\n",
       "            p_layer2_0_bn1_bias: PARAMETER target='layer2.0.bn1.bias'\n",
       "            p_layer2_0_conv2_weight: PARAMETER target='layer2.0.conv2.weight'\n",
       "            p_layer2_0_bn2_weight: PARAMETER target='layer2.0.bn2.weight'\n",
       "            p_layer2_0_bn2_bias: PARAMETER target='layer2.0.bn2.bias'\n",
       "            p_layer2_0_downsample_0_weight: PARAMETER target='layer2.0.downsample.0.weight'\n",
       "            p_layer2_0_downsample_1_weight: PARAMETER target='layer2.0.downsample.1.weight'\n",
       "            p_layer2_0_downsample_1_bias: PARAMETER target='layer2.0.downsample.1.bias'\n",
       "            p_layer2_1_conv1_weight: PARAMETER target='layer2.1.conv1.weight'\n",
       "            p_layer2_1_bn1_weight: PARAMETER target='layer2.1.bn1.weight'\n",
       "            p_layer2_1_bn1_bias: PARAMETER target='layer2.1.bn1.bias'\n",
       "            p_layer2_1_conv2_weight: PARAMETER target='layer2.1.conv2.weight'\n",
       "            p_layer2_1_bn2_weight: PARAMETER target='layer2.1.bn2.weight'\n",
       "            p_layer2_1_bn2_bias: PARAMETER target='layer2.1.bn2.bias'\n",
       "            p_layer3_0_conv1_weight: PARAMETER target='layer3.0.conv1.weight'\n",
       "            p_layer3_0_bn1_weight: PARAMETER target='layer3.0.bn1.weight'\n",
       "            p_layer3_0_bn1_bias: PARAMETER target='layer3.0.bn1.bias'\n",
       "            p_layer3_0_conv2_weight: PARAMETER target='layer3.0.conv2.weight'\n",
       "            p_layer3_0_bn2_weight: PARAMETER target='layer3.0.bn2.weight'\n",
       "            p_layer3_0_bn2_bias: PARAMETER target='layer3.0.bn2.bias'\n",
       "            p_layer3_0_downsample_0_weight: PARAMETER target='layer3.0.downsample.0.weight'\n",
       "            p_layer3_0_downsample_1_weight: PARAMETER target='layer3.0.downsample.1.weight'\n",
       "            p_layer3_0_downsample_1_bias: PARAMETER target='layer3.0.downsample.1.bias'\n",
       "            p_layer3_1_conv1_weight: PARAMETER target='layer3.1.conv1.weight'\n",
       "            p_layer3_1_bn1_weight: PARAMETER target='layer3.1.bn1.weight'\n",
       "            p_layer3_1_bn1_bias: PARAMETER target='layer3.1.bn1.bias'\n",
       "            p_layer3_1_conv2_weight: PARAMETER target='layer3.1.conv2.weight'\n",
       "            p_layer3_1_bn2_weight: PARAMETER target='layer3.1.bn2.weight'\n",
       "            p_layer3_1_bn2_bias: PARAMETER target='layer3.1.bn2.bias'\n",
       "            p_layer4_0_conv1_weight: PARAMETER target='layer4.0.conv1.weight'\n",
       "            p_layer4_0_bn1_weight: PARAMETER target='layer4.0.bn1.weight'\n",
       "            p_layer4_0_bn1_bias: PARAMETER target='layer4.0.bn1.bias'\n",
       "            p_layer4_0_conv2_weight: PARAMETER target='layer4.0.conv2.weight'\n",
       "            p_layer4_0_bn2_weight: PARAMETER target='layer4.0.bn2.weight'\n",
       "            p_layer4_0_bn2_bias: PARAMETER target='layer4.0.bn2.bias'\n",
       "            p_layer4_0_downsample_0_weight: PARAMETER target='layer4.0.downsample.0.weight'\n",
       "            p_layer4_0_downsample_1_weight: PARAMETER target='layer4.0.downsample.1.weight'\n",
       "            p_layer4_0_downsample_1_bias: PARAMETER target='layer4.0.downsample.1.bias'\n",
       "            p_layer4_1_conv1_weight: PARAMETER target='layer4.1.conv1.weight'\n",
       "            p_layer4_1_bn1_weight: PARAMETER target='layer4.1.bn1.weight'\n",
       "            p_layer4_1_bn1_bias: PARAMETER target='layer4.1.bn1.bias'\n",
       "            p_layer4_1_conv2_weight: PARAMETER target='layer4.1.conv2.weight'\n",
       "            p_layer4_1_bn2_weight: PARAMETER target='layer4.1.bn2.weight'\n",
       "            p_layer4_1_bn2_bias: PARAMETER target='layer4.1.bn2.bias'\n",
       "            p_fc_weight: PARAMETER target='fc.weight'\n",
       "            p_fc_bias: PARAMETER target='fc.bias'\n",
       "            b_bn1_running_mean: BUFFER target='bn1.running_mean' persistent=True\n",
       "            b_bn1_running_var: BUFFER target='bn1.running_var' persistent=True\n",
       "            b_bn1_num_batches_tracked: BUFFER target='bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_0_bn1_running_mean: BUFFER target='layer1.0.bn1.running_mean' persistent=True\n",
       "            b_layer1_0_bn1_running_var: BUFFER target='layer1.0.bn1.running_var' persistent=True\n",
       "            b_layer1_0_bn1_num_batches_tracked: BUFFER target='layer1.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_0_bn2_running_mean: BUFFER target='layer1.0.bn2.running_mean' persistent=True\n",
       "            b_layer1_0_bn2_running_var: BUFFER target='layer1.0.bn2.running_var' persistent=True\n",
       "            b_layer1_0_bn2_num_batches_tracked: BUFFER target='layer1.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer1_1_bn1_running_mean: BUFFER target='layer1.1.bn1.running_mean' persistent=True\n",
       "            b_layer1_1_bn1_running_var: BUFFER target='layer1.1.bn1.running_var' persistent=True\n",
       "            b_layer1_1_bn1_num_batches_tracked: BUFFER target='layer1.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_1_bn2_running_mean: BUFFER target='layer1.1.bn2.running_mean' persistent=True\n",
       "            b_layer1_1_bn2_running_var: BUFFER target='layer1.1.bn2.running_var' persistent=True\n",
       "            b_layer1_1_bn2_num_batches_tracked: BUFFER target='layer1.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_bn1_running_mean: BUFFER target='layer2.0.bn1.running_mean' persistent=True\n",
       "            b_layer2_0_bn1_running_var: BUFFER target='layer2.0.bn1.running_var' persistent=True\n",
       "            b_layer2_0_bn1_num_batches_tracked: BUFFER target='layer2.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_bn2_running_mean: BUFFER target='layer2.0.bn2.running_mean' persistent=True\n",
       "            b_layer2_0_bn2_running_var: BUFFER target='layer2.0.bn2.running_var' persistent=True\n",
       "            b_layer2_0_bn2_num_batches_tracked: BUFFER target='layer2.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_downsample_1_running_mean: BUFFER target='layer2.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer2_0_downsample_1_running_var: BUFFER target='layer2.0.downsample.1.running_var' persistent=True\n",
       "            b_layer2_0_downsample_1_num_batches_tracked: BUFFER target='layer2.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer2_1_bn1_running_mean: BUFFER target='layer2.1.bn1.running_mean' persistent=True\n",
       "            b_layer2_1_bn1_running_var: BUFFER target='layer2.1.bn1.running_var' persistent=True\n",
       "            b_layer2_1_bn1_num_batches_tracked: BUFFER target='layer2.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_1_bn2_running_mean: BUFFER target='layer2.1.bn2.running_mean' persistent=True\n",
       "            b_layer2_1_bn2_running_var: BUFFER target='layer2.1.bn2.running_var' persistent=True\n",
       "            b_layer2_1_bn2_num_batches_tracked: BUFFER target='layer2.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_bn1_running_mean: BUFFER target='layer3.0.bn1.running_mean' persistent=True\n",
       "            b_layer3_0_bn1_running_var: BUFFER target='layer3.0.bn1.running_var' persistent=True\n",
       "            b_layer3_0_bn1_num_batches_tracked: BUFFER target='layer3.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_bn2_running_mean: BUFFER target='layer3.0.bn2.running_mean' persistent=True\n",
       "            b_layer3_0_bn2_running_var: BUFFER target='layer3.0.bn2.running_var' persistent=True\n",
       "            b_layer3_0_bn2_num_batches_tracked: BUFFER target='layer3.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_downsample_1_running_mean: BUFFER target='layer3.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer3_0_downsample_1_running_var: BUFFER target='layer3.0.downsample.1.running_var' persistent=True\n",
       "            b_layer3_0_downsample_1_num_batches_tracked: BUFFER target='layer3.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer3_1_bn1_running_mean: BUFFER target='layer3.1.bn1.running_mean' persistent=True\n",
       "            b_layer3_1_bn1_running_var: BUFFER target='layer3.1.bn1.running_var' persistent=True\n",
       "            b_layer3_1_bn1_num_batches_tracked: BUFFER target='layer3.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_1_bn2_running_mean: BUFFER target='layer3.1.bn2.running_mean' persistent=True\n",
       "            b_layer3_1_bn2_running_var: BUFFER target='layer3.1.bn2.running_var' persistent=True\n",
       "            b_layer3_1_bn2_num_batches_tracked: BUFFER target='layer3.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer4_0_bn1_running_mean: BUFFER target='layer4.0.bn1.running_mean' persistent=True\n",
       "            b_layer4_0_bn1_running_var: BUFFER target='layer4.0.bn1.running_var' persistent=True\n",
       "            b_layer4_0_bn1_num_batches_tracked: BUFFER target='layer4.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer4_0_bn2_running_mean: BUFFER target='layer4.0.bn2.running_mean' persistent=True\n",
       "            b_layer4_0_bn2_running_var: BUFFER target='layer4.0.bn2.running_var' persistent=True\n",
       "            b_layer4_0_bn2_num_batches_tracked: BUFFER target='layer4.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer4_0_downsample_1_running_mean: BUFFER target='layer4.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer4_0_downsample_1_running_var: BUFFER target='layer4.0.downsample.1.running_var' persistent=True\n",
       "            b_layer4_0_downsample_1_num_batches_tracked: BUFFER target='layer4.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer4_1_bn1_running_mean: BUFFER target='layer4.1.bn1.running_mean' persistent=True\n",
       "            b_layer4_1_bn1_running_var: BUFFER target='layer4.1.bn1.running_var' persistent=True\n",
       "            b_layer4_1_bn1_num_batches_tracked: BUFFER target='layer4.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer4_1_bn2_running_mean: BUFFER target='layer4.1.bn2.running_mean' persistent=True\n",
       "            b_layer4_1_bn2_running_var: BUFFER target='layer4.1.bn2.running_var' persistent=True\n",
       "            b_layer4_1_bn2_num_batches_tracked: BUFFER target='layer4.1.bn2.num_batches_tracked' persistent=True\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=12\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
