{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec5ee81",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc9eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab055f",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90e8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'leafs', 'metal', 'paper', 'plastic_bag', 'plastic_bottle']\n",
      "Train size: 52669\n",
      "Validation size: 13168\n",
      "Train class counts: Counter({np.int64(1): 12689, np.int64(3): 8522, np.int64(8): 8000, np.int64(7): 7107, np.int64(4): 4450, np.int64(5): 3595, np.int64(2): 2626, np.int64(9): 2421, np.int64(6): 1748, np.int64(0): 1511})\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"dataset\"\n",
    "train_ratio = 0.8\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=root_dir)\n",
    "targets = np.array(full_dataset.targets)\n",
    "indices = np.arange(len(targets))\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=1 - train_ratio,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(datasets.ImageFolder(root=root_dir, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(datasets.ImageFolder(root=root_dir, transform=val_transform), val_idx)\n",
    "\n",
    "train_targets = targets[train_idx]\n",
    "class_counts = Counter(train_targets)\n",
    "num_samples = len(train_dataset)\n",
    "\n",
    "class_weights = {cls: num_samples / count for cls, count in class_counts.items()}\n",
    "sample_weights = [class_weights[t] for t in train_targets]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    sampler=sampler,\n",
    "    num_workers=num_workers)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "print(\"Classes:\", full_dataset.classes)\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(val_dataset))\n",
    "print(\"Train class counts:\", class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb64b04",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69be00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f166da",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436e75d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912e6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Train Loss: 0.3779 | Train Acc: 0.8742 | Val Loss: 0.1222 | Val Acc: 0.9613 | F1 (macro): 0.9476\n",
      "Epoch [2/15] Train Loss: 0.2536 | Train Acc: 0.9163 | Val Loss: 0.1602 | Val Acc: 0.9493 | F1 (macro): 0.9281\n",
      "Epoch [3/15] Train Loss: 0.2110 | Train Acc: 0.9294 | Val Loss: 0.0985 | Val Acc: 0.9683 | F1 (macro): 0.9566\n",
      "Epoch [4/15] Train Loss: 0.1912 | Train Acc: 0.9356 | Val Loss: 0.1110 | Val Acc: 0.9639 | F1 (macro): 0.9564\n",
      "Epoch [5/15] Train Loss: 0.1770 | Train Acc: 0.9408 | Val Loss: 0.0943 | Val Acc: 0.9707 | F1 (macro): 0.9596\n",
      "Epoch [6/15] Train Loss: 0.1636 | Train Acc: 0.9454 | Val Loss: 0.1087 | Val Acc: 0.9681 | F1 (macro): 0.9550\n",
      "Epoch [7/15] Train Loss: 0.1540 | Train Acc: 0.9481 | Val Loss: 0.0817 | Val Acc: 0.9743 | F1 (macro): 0.9668\n",
      "Epoch [8/15] Train Loss: 0.1478 | Train Acc: 0.9504 | Val Loss: 0.0830 | Val Acc: 0.9740 | F1 (macro): 0.9652\n",
      "Epoch [9/15] Train Loss: 0.1432 | Train Acc: 0.9521 | Val Loss: 0.0886 | Val Acc: 0.9727 | F1 (macro): 0.9625\n",
      "Epoch [10/15] Train Loss: 0.1316 | Train Acc: 0.9559 | Val Loss: 0.0719 | Val Acc: 0.9776 | F1 (macro): 0.9698\n",
      "Epoch [11/15] Train Loss: 0.1287 | Train Acc: 0.9576 | Val Loss: 0.0670 | Val Acc: 0.9798 | F1 (macro): 0.9735\n",
      "Epoch [12/15] Train Loss: 0.1231 | Train Acc: 0.9590 | Val Loss: 0.0826 | Val Acc: 0.9765 | F1 (macro): 0.9702\n",
      "Epoch [13/15] Train Loss: 0.1218 | Train Acc: 0.9594 | Val Loss: 0.0585 | Val Acc: 0.9831 | F1 (macro): 0.9768\n",
      "Epoch [14/15] Train Loss: 0.1177 | Train Acc: 0.9609 | Val Loss: 0.0731 | Val Acc: 0.9791 | F1 (macro): 0.9732\n",
      "Epoch [15/15] Train Loss: 0.1148 | Train Acc: 0.9612 | Val Loss: 0.0708 | Val Acc: 0.9803 | F1 (macro): 0.9729\n",
      "\n",
      "Final classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       battery       0.96      0.97      0.96       378\n",
      "    biological       0.99      0.96      0.98      3173\n",
      "     cardboard       0.95      0.98      0.96       656\n",
      "       clothes       0.99      1.00      1.00      2130\n",
      "         glass       0.96      0.98      0.97      1113\n",
      "         leafs       1.00      1.00      1.00       899\n",
      "         metal       0.92      0.96      0.94       437\n",
      "         paper       0.98      0.99      0.98      1777\n",
      "   plastic_bag       1.00      1.00      1.00      2000\n",
      "plastic_bottle       0.93      0.96      0.95       605\n",
      "\n",
      "      accuracy                           0.98     13168\n",
      "     macro avg       0.97      0.98      0.97     13168\n",
      "  weighted avg       0.98      0.98      0.98     13168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "        f\"F1 (macro): {f1_macro:.4f}\")\n",
    "\n",
    "print(\"\\nFinal classification report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=full_dataset.classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e40d0b",
   "metadata": {},
   "source": [
    "# Exporting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a6ceb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa4aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1113 02:06:17.013000 4676 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
      "Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 40 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 18},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu126',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,3,224,224]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,10]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"fc.bias\"<FLOAT,[10]>{TorchTensor<FLOAT,[10]>(Parameter containing: tensor([ 0.0095, -0.0285,  0.0242, -0.0329,  0.0034,  0.0123,  0.0186, -0.0023, -0.0275,  0.0282], device='cuda:0', requires_grad=True), name='fc.bias')},\n",
       "                %\"conv1.weight\"<FLOAT,[64,3,7,7]>{Tensor(...)},\n",
       "                %\"layer1.0.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer1.0.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer1.1.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer1.1.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"layer2.0.conv1.weight\"<FLOAT,[128,64,3,3]>{Tensor(...)},\n",
       "                %\"layer2.0.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"layer2.0.downsample.0.weight\"<FLOAT,[128,64,1,1]>{Tensor(...)},\n",
       "                %\"layer2.1.conv1.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"layer2.1.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"layer3.0.conv1.weight\"<FLOAT,[256,128,3,3]>{Tensor(...)},\n",
       "                %\"layer3.0.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"layer3.0.downsample.0.weight\"<FLOAT,[256,128,1,1]>{Tensor(...)},\n",
       "                %\"layer3.1.conv1.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"layer3.1.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"layer4.0.conv1.weight\"<FLOAT,[512,256,3,3]>{Tensor(...)},\n",
       "                %\"layer4.0.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"layer4.0.downsample.0.weight\"<FLOAT,[512,256,1,1]>{Tensor(...)},\n",
       "                %\"layer4.1.conv1.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"layer4.1.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"fc.weight\"<FLOAT,[10,512]>{TorchTensor(...)},\n",
       "                %\"val_186\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_186')},\n",
       "                %\"val_190\"<INT64,[2]>{Tensor<INT64,[2]>(array([  1, 512]), name='val_190')},\n",
       "                %\"input_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"max_pool2d_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_1_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_2_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_3_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_4_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_5_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_6_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_7_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_8_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_9_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_10_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_11_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_12_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_13_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_14_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_15_bias\"<FLOAT,[512]>{Tensor(...)}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Conv_251\n",
       "                  %\"getitem\"<FLOAT,[1,64,112,112]> ⬅️ ::Conv(%\"input\", %\"conv1.weight\"{...}, %\"input_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(3, 3, 3, 3)}\n",
       "             1 |  # node_relu\n",
       "                  %\"relu\"<FLOAT,[1,64,112,112]> ⬅️ ::Relu(%\"getitem\")\n",
       "             2 |  # node_max_pool2d\n",
       "                  %\"max_pool2d\"<FLOAT,[1,64,56,56]>, %\"\"<?,?> ⬅️ ::MaxPool(%\"relu\") {kernel_shape=(3, 3), strides=(2, 2), dilations=(1, 1), auto_pad='NOTSET', pads=(1, 1, 1, 1), ceil_mode=0, storage_order=0}\n",
       "             3 |  # node_Conv_253\n",
       "                  %\"getitem_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"max_pool2d\", %\"layer1.0.conv1.weight\"{...}, %\"max_pool2d_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             4 |  # node_relu_1\n",
       "                  %\"relu_1\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_3\")\n",
       "             5 |  # node_Conv_255\n",
       "                  %\"getitem_6\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_1\", %\"layer1.0.conv2.weight\"{...}, %\"relu_1_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             6 |  # node_add\n",
       "                  %\"add\"<FLOAT,[1,64,56,56]> ⬅️ ::Add(%\"getitem_6\", %\"max_pool2d\")\n",
       "             7 |  # node_relu_2\n",
       "                  %\"relu_2\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"add\")\n",
       "             8 |  # node_Conv_257\n",
       "                  %\"getitem_9\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_2\", %\"layer1.1.conv1.weight\"{...}, %\"relu_2_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             9 |  # node_relu_3\n",
       "                  %\"relu_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_9\")\n",
       "            10 |  # node_Conv_259\n",
       "                  %\"getitem_12\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_3\", %\"layer1.1.conv2.weight\"{...}, %\"relu_3_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            11 |  # node_add_1\n",
       "                  %\"add_1\"<FLOAT,[1,64,56,56]> ⬅️ ::Add(%\"getitem_12\", %\"relu_2\")\n",
       "            12 |  # node_relu_4\n",
       "                  %\"relu_4\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"add_1\")\n",
       "            13 |  # node_Conv_261\n",
       "                  %\"getitem_15\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_4\", %\"layer2.0.conv1.weight\"{...}, %\"relu_4_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            14 |  # node_relu_5\n",
       "                  %\"relu_5\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_15\")\n",
       "            15 |  # node_Conv_263\n",
       "                  %\"getitem_18\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_5\", %\"layer2.0.conv2.weight\"{...}, %\"relu_5_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            16 |  # node_Conv_265\n",
       "                  %\"getitem_21\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_4\", %\"layer2.0.downsample.0.weight\"{...}, %\"relu_4_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            17 |  # node_add_2\n",
       "                  %\"add_2\"<FLOAT,[1,128,28,28]> ⬅️ ::Add(%\"getitem_18\", %\"getitem_21\")\n",
       "            18 |  # node_relu_6\n",
       "                  %\"relu_6\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"add_2\")\n",
       "            19 |  # node_Conv_267\n",
       "                  %\"getitem_24\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_6\", %\"layer2.1.conv1.weight\"{...}, %\"relu_6_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            20 |  # node_relu_7\n",
       "                  %\"relu_7\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_24\")\n",
       "            21 |  # node_Conv_269\n",
       "                  %\"getitem_27\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_7\", %\"layer2.1.conv2.weight\"{...}, %\"relu_7_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            22 |  # node_add_3\n",
       "                  %\"add_3\"<FLOAT,[1,128,28,28]> ⬅️ ::Add(%\"getitem_27\", %\"relu_6\")\n",
       "            23 |  # node_relu_8\n",
       "                  %\"relu_8\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"add_3\")\n",
       "            24 |  # node_Conv_271\n",
       "                  %\"getitem_30\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_8\", %\"layer3.0.conv1.weight\"{...}, %\"relu_8_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            25 |  # node_relu_9\n",
       "                  %\"relu_9\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_30\")\n",
       "            26 |  # node_Conv_273\n",
       "                  %\"getitem_33\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_9\", %\"layer3.0.conv2.weight\"{...}, %\"relu_9_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            27 |  # node_Conv_275\n",
       "                  %\"getitem_36\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_8\", %\"layer3.0.downsample.0.weight\"{...}, %\"relu_8_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            28 |  # node_add_4\n",
       "                  %\"add_4\"<FLOAT,[1,256,14,14]> ⬅️ ::Add(%\"getitem_33\", %\"getitem_36\")\n",
       "            29 |  # node_relu_10\n",
       "                  %\"relu_10\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"add_4\")\n",
       "            30 |  # node_Conv_277\n",
       "                  %\"getitem_39\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_10\", %\"layer3.1.conv1.weight\"{...}, %\"relu_10_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            31 |  # node_relu_11\n",
       "                  %\"relu_11\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_39\")\n",
       "            32 |  # node_Conv_279\n",
       "                  %\"getitem_42\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_11\", %\"layer3.1.conv2.weight\"{...}, %\"relu_11_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            33 |  # node_add_5\n",
       "                  %\"add_5\"<FLOAT,[1,256,14,14]> ⬅️ ::Add(%\"getitem_42\", %\"relu_10\")\n",
       "            34 |  # node_relu_12\n",
       "                  %\"relu_12\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"add_5\")\n",
       "            35 |  # node_Conv_281\n",
       "                  %\"getitem_45\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_12\", %\"layer4.0.conv1.weight\"{...}, %\"relu_12_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            36 |  # node_relu_13\n",
       "                  %\"relu_13\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_45\")\n",
       "            37 |  # node_Conv_283\n",
       "                  %\"getitem_48\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_13\", %\"layer4.0.conv2.weight\"{...}, %\"relu_13_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            38 |  # node_Conv_285\n",
       "                  %\"getitem_51\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_12\", %\"layer4.0.downsample.0.weight\"{...}, %\"relu_12_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            39 |  # node_add_6\n",
       "                  %\"add_6\"<FLOAT,[1,512,7,7]> ⬅️ ::Add(%\"getitem_48\", %\"getitem_51\")\n",
       "            40 |  # node_relu_14\n",
       "                  %\"relu_14\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"add_6\")\n",
       "            41 |  # node_Conv_287\n",
       "                  %\"getitem_54\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_14\", %\"layer4.1.conv1.weight\"{...}, %\"relu_14_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            42 |  # node_relu_15\n",
       "                  %\"relu_15\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_54\")\n",
       "            43 |  # node_Conv_289\n",
       "                  %\"getitem_57\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_15\", %\"layer4.1.conv2.weight\"{...}, %\"relu_15_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            44 |  # node_add_7\n",
       "                  %\"add_7\"<FLOAT,[1,512,7,7]> ⬅️ ::Add(%\"getitem_57\", %\"relu_14\")\n",
       "            45 |  # node_relu_16\n",
       "                  %\"relu_16\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"add_7\")\n",
       "            46 |  # node_mean\n",
       "                  %\"mean\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"relu_16\", %\"val_186\"{[-1, -2]}) {keepdims=1, noop_with_empty_axes=0}\n",
       "            47 |  # node_view\n",
       "                  %\"view\"<FLOAT,[1,512]> ⬅️ ::Reshape(%\"mean\", %\"val_190\"{[1, 512]}) {allowzero=1}\n",
       "            48 |  # node_linear\n",
       "                  %\"output\"<FLOAT,[1,10]> ⬅️ ::Gemm(%\"view\", %\"fc.weight\"{...}, %\"fc.bias\"{[0.009455682709813118, -0.028462398797273636, 0.024228185415267944, -0.03285178914666176, 0.0033584139309823513, 0.012283574789762497, 0.018610933795571327, -0.0023425521794706583, -0.027528615668416023, 0.028171012178063393]}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            return %\"output\"<FLOAT,[1,10]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_conv1_weight: \"f32[64, 3, 7, 7]\", p_bn1_weight: \"f32[64]\", p_bn1_bias: \"f32[64]\", p_layer1_0_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn1_weight: \"f32[64]\", p_layer1_0_bn1_bias: \"f32[64]\", p_layer1_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn2_weight: \"f32[64]\", p_layer1_0_bn2_bias: \"f32[64]\", p_layer1_1_conv1_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn1_weight: \"f32[64]\", p_layer1_1_bn1_bias: \"f32[64]\", p_layer1_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn2_weight: \"f32[64]\", p_layer1_1_bn2_bias: \"f32[64]\", p_layer2_0_conv1_weight: \"f32[128, 64, 3, 3]\", p_layer2_0_bn1_weight: \"f32[128]\", p_layer2_0_bn1_bias: \"f32[128]\", p_layer2_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_0_bn2_weight: \"f32[128]\", p_layer2_0_bn2_bias: \"f32[128]\", p_layer2_0_downsample_0_weight: \"f32[128, 64, 1, 1]\", p_layer2_0_downsample_1_weight: \"f32[128]\", p_layer2_0_downsample_1_bias: \"f32[128]\", p_layer2_1_conv1_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn1_weight: \"f32[128]\", p_layer2_1_bn1_bias: \"f32[128]\", p_layer2_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn2_weight: \"f32[128]\", p_layer2_1_bn2_bias: \"f32[128]\", p_layer3_0_conv1_weight: \"f32[256, 128, 3, 3]\", p_layer3_0_bn1_weight: \"f32[256]\", p_layer3_0_bn1_bias: \"f32[256]\", p_layer3_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_0_bn2_weight: \"f32[256]\", p_layer3_0_bn2_bias: \"f32[256]\", p_layer3_0_downsample_0_weight: \"f32[256, 128, 1, 1]\", p_layer3_0_downsample_1_weight: \"f32[256]\", p_layer3_0_downsample_1_bias: \"f32[256]\", p_layer3_1_conv1_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn1_weight: \"f32[256]\", p_layer3_1_bn1_bias: \"f32[256]\", p_layer3_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn2_weight: \"f32[256]\", p_layer3_1_bn2_bias: \"f32[256]\", p_layer4_0_conv1_weight: \"f32[512, 256, 3, 3]\", p_layer4_0_bn1_weight: \"f32[512]\", p_layer4_0_bn1_bias: \"f32[512]\", p_layer4_0_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_0_bn2_weight: \"f32[512]\", p_layer4_0_bn2_bias: \"f32[512]\", p_layer4_0_downsample_0_weight: \"f32[512, 256, 1, 1]\", p_layer4_0_downsample_1_weight: \"f32[512]\", p_layer4_0_downsample_1_bias: \"f32[512]\", p_layer4_1_conv1_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn1_weight: \"f32[512]\", p_layer4_1_bn1_bias: \"f32[512]\", p_layer4_1_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn2_weight: \"f32[512]\", p_layer4_1_bn2_bias: \"f32[512]\", p_fc_weight: \"f32[10, 512]\", p_fc_bias: \"f32[10]\", b_bn1_running_mean: \"f32[64]\", b_bn1_running_var: \"f32[64]\", b_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn1_running_mean: \"f32[64]\", b_layer1_0_bn1_running_var: \"f32[64]\", b_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn2_running_mean: \"f32[64]\", b_layer1_0_bn2_running_var: \"f32[64]\", b_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_layer1_1_bn1_running_mean: \"f32[64]\", b_layer1_1_bn1_running_var: \"f32[64]\", b_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_layer1_1_bn2_running_mean: \"f32[64]\", b_layer1_1_bn2_running_var: \"f32[64]\", b_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_bn1_running_mean: \"f32[128]\", b_layer2_0_bn1_running_var: \"f32[128]\", b_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_layer2_0_bn2_running_mean: \"f32[128]\", b_layer2_0_bn2_running_var: \"f32[128]\", b_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_downsample_1_running_mean: \"f32[128]\", b_layer2_0_downsample_1_running_var: \"f32[128]\", b_layer2_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer2_1_bn1_running_mean: \"f32[128]\", b_layer2_1_bn1_running_var: \"f32[128]\", b_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_layer2_1_bn2_running_mean: \"f32[128]\", b_layer2_1_bn2_running_var: \"f32[128]\", b_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_bn1_running_mean: \"f32[256]\", b_layer3_0_bn1_running_var: \"f32[256]\", b_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_layer3_0_bn2_running_mean: \"f32[256]\", b_layer3_0_bn2_running_var: \"f32[256]\", b_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_downsample_1_running_mean: \"f32[256]\", b_layer3_0_downsample_1_running_var: \"f32[256]\", b_layer3_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer3_1_bn1_running_mean: \"f32[256]\", b_layer3_1_bn1_running_var: \"f32[256]\", b_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_layer3_1_bn2_running_mean: \"f32[256]\", b_layer3_1_bn2_running_var: \"f32[256]\", b_layer3_1_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_bn1_running_mean: \"f32[512]\", b_layer4_0_bn1_running_var: \"f32[512]\", b_layer4_0_bn1_num_batches_tracked: \"i64[]\", b_layer4_0_bn2_running_mean: \"f32[512]\", b_layer4_0_bn2_running_var: \"f32[512]\", b_layer4_0_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_downsample_1_running_mean: \"f32[512]\", b_layer4_0_downsample_1_running_var: \"f32[512]\", b_layer4_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer4_1_bn1_running_mean: \"f32[512]\", b_layer4_1_bn1_running_var: \"f32[512]\", b_layer4_1_bn1_num_batches_tracked: \"i64[]\", b_layer4_1_bn2_running_mean: \"f32[512]\", b_layer4_1_bn2_running_var: \"f32[512]\", b_layer4_1_bn2_num_batches_tracked: \"i64[]\", x: \"f32[1, 3, 224, 224]\"):\n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[1, 64, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_conv1_weight, None, [2, 2], [3, 3]);  x = p_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_bn1_weight, p_bn1_bias, b_bn1_running_mean, b_bn1_running_var, 0.1, 1e-05);  conv2d = p_bn1_weight = p_bn1_bias = b_bn1_running_mean = b_bn1_running_var = None\n",
       "                    getitem: \"f32[1, 64, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[1, 64, 112, 112]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:226 in forward, code: return F.max_pool2d(\n",
       "                    max_pool2d: \"f32[1, 64, 56, 56]\" = torch.ops.aten.max_pool2d.default(relu, [3, 3], [2, 2], [1, 1]);  relu = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_layer1_0_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_layer1_0_bn1_weight, p_layer1_0_bn1_bias, b_layer1_0_bn1_running_mean, b_layer1_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_layer1_0_bn1_weight = p_layer1_0_bn1_bias = b_layer1_0_bn1_running_mean = b_layer1_0_bn1_running_var = None\n",
       "                    getitem_3: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_1, p_layer1_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_layer1_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_layer1_0_bn2_weight, p_layer1_0_bn2_bias, b_layer1_0_bn2_running_mean, b_layer1_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_layer1_0_bn2_weight = p_layer1_0_bn2_bias = b_layer1_0_bn2_running_mean = b_layer1_0_bn2_running_var = None\n",
       "                    getitem_6: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add: \"f32[1, 64, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_6, max_pool2d);  getitem_6 = max_pool2d = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(add);  add = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_2, p_layer1_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer1_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_layer1_1_bn1_weight, p_layer1_1_bn1_bias, b_layer1_1_bn1_running_mean, b_layer1_1_bn1_running_var, 0.1, 1e-05);  conv2d_3 = p_layer1_1_bn1_weight = p_layer1_1_bn1_bias = b_layer1_1_bn1_running_mean = b_layer1_1_bn1_running_var = None\n",
       "                    getitem_9: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_3: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_3, p_layer1_1_conv2_weight, None, [1, 1], [1, 1]);  relu_3 = p_layer1_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_layer1_1_bn2_weight, p_layer1_1_bn2_bias, b_layer1_1_bn2_running_mean, b_layer1_1_bn2_running_var, 0.1, 1e-05);  conv2d_4 = p_layer1_1_bn2_weight = p_layer1_1_bn2_bias = b_layer1_1_bn2_running_mean = b_layer1_1_bn2_running_var = None\n",
       "                    getitem_12: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_12, relu_2);  getitem_12 = relu_2 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(add_1);  add_1 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_4, p_layer2_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer2_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_layer2_0_bn1_weight, p_layer2_0_bn1_bias, b_layer2_0_bn1_running_mean, b_layer2_0_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_layer2_0_bn1_weight = p_layer2_0_bn1_bias = b_layer2_0_bn1_running_mean = b_layer2_0_bn1_running_var = None\n",
       "                    getitem_15: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_5: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_5, p_layer2_0_conv2_weight, None, [1, 1], [1, 1]);  relu_5 = p_layer2_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_layer2_0_bn2_weight, p_layer2_0_bn2_bias, b_layer2_0_bn2_running_mean, b_layer2_0_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_layer2_0_bn2_weight = p_layer2_0_bn2_bias = b_layer2_0_bn2_running_mean = b_layer2_0_bn2_running_var = None\n",
       "                    getitem_18: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_4, p_layer2_0_downsample_0_weight, None, [2, 2]);  relu_4 = p_layer2_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_layer2_0_downsample_1_weight, p_layer2_0_downsample_1_bias, b_layer2_0_downsample_1_running_mean, b_layer2_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_7 = p_layer2_0_downsample_1_weight = p_layer2_0_downsample_1_bias = b_layer2_0_downsample_1_running_mean = b_layer2_0_downsample_1_running_var = None\n",
       "                    getitem_21: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_2: \"f32[1, 128, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_18, getitem_21);  getitem_18 = getitem_21 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_6: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(add_2);  add_2 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_6, p_layer2_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer2_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_layer2_1_bn1_weight, p_layer2_1_bn1_bias, b_layer2_1_bn1_running_mean, b_layer2_1_bn1_running_var, 0.1, 1e-05);  conv2d_8 = p_layer2_1_bn1_weight = p_layer2_1_bn1_bias = b_layer2_1_bn1_running_mean = b_layer2_1_bn1_running_var = None\n",
       "                    getitem_24: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_7: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_7, p_layer2_1_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_layer2_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_layer2_1_bn2_weight, p_layer2_1_bn2_bias, b_layer2_1_bn2_running_mean, b_layer2_1_bn2_running_var, 0.1, 1e-05);  conv2d_9 = p_layer2_1_bn2_weight = p_layer2_1_bn2_bias = b_layer2_1_bn2_running_mean = b_layer2_1_bn2_running_var = None\n",
       "                    getitem_27: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_3: \"f32[1, 128, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_27, relu_6);  getitem_27 = relu_6 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_8: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(add_3);  add_3 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_8, p_layer3_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer3_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_layer3_0_bn1_weight, p_layer3_0_bn1_bias, b_layer3_0_bn1_running_mean, b_layer3_0_bn1_running_var, 0.1, 1e-05);  conv2d_10 = p_layer3_0_bn1_weight = p_layer3_0_bn1_bias = b_layer3_0_bn1_running_mean = b_layer3_0_bn1_running_var = None\n",
       "                    getitem_30: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_9: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_9, p_layer3_0_conv2_weight, None, [1, 1], [1, 1]);  relu_9 = p_layer3_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_layer3_0_bn2_weight, p_layer3_0_bn2_bias, b_layer3_0_bn2_running_mean, b_layer3_0_bn2_running_var, 0.1, 1e-05);  conv2d_11 = p_layer3_0_bn2_weight = p_layer3_0_bn2_bias = b_layer3_0_bn2_running_mean = b_layer3_0_bn2_running_var = None\n",
       "                    getitem_33: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_8, p_layer3_0_downsample_0_weight, None, [2, 2]);  relu_8 = p_layer3_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_layer3_0_downsample_1_weight, p_layer3_0_downsample_1_bias, b_layer3_0_downsample_1_running_mean, b_layer3_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_12 = p_layer3_0_downsample_1_weight = p_layer3_0_downsample_1_bias = b_layer3_0_downsample_1_running_mean = b_layer3_0_downsample_1_running_var = None\n",
       "                    getitem_36: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_4: \"f32[1, 256, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_33, getitem_36);  getitem_33 = getitem_36 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_10: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(add_4);  add_4 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_10, p_layer3_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer3_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_layer3_1_bn1_weight, p_layer3_1_bn1_bias, b_layer3_1_bn1_running_mean, b_layer3_1_bn1_running_var, 0.1, 1e-05);  conv2d_13 = p_layer3_1_bn1_weight = p_layer3_1_bn1_bias = b_layer3_1_bn1_running_mean = b_layer3_1_bn1_running_var = None\n",
       "                    getitem_39: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_11: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_39);  getitem_39 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_11, p_layer3_1_conv2_weight, None, [1, 1], [1, 1]);  relu_11 = p_layer3_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_layer3_1_bn2_weight, p_layer3_1_bn2_bias, b_layer3_1_bn2_running_mean, b_layer3_1_bn2_running_var, 0.1, 1e-05);  conv2d_14 = p_layer3_1_bn2_weight = p_layer3_1_bn2_bias = b_layer3_1_bn2_running_mean = b_layer3_1_bn2_running_var = None\n",
       "                    getitem_42: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_5: \"f32[1, 256, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_42, relu_10);  getitem_42 = relu_10 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(add_5);  add_5 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_15: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_12, p_layer4_0_conv1_weight, None, [2, 2], [1, 1]);  p_layer4_0_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_layer4_0_bn1_weight, p_layer4_0_bn1_bias, b_layer4_0_bn1_running_mean, b_layer4_0_bn1_running_var, 0.1, 1e-05);  conv2d_15 = p_layer4_0_bn1_weight = p_layer4_0_bn1_bias = b_layer4_0_bn1_running_mean = b_layer4_0_bn1_running_var = None\n",
       "                    getitem_45: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_13: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_16: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_13, p_layer4_0_conv2_weight, None, [1, 1], [1, 1]);  relu_13 = p_layer4_0_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_layer4_0_bn2_weight, p_layer4_0_bn2_bias, b_layer4_0_bn2_running_mean, b_layer4_0_bn2_running_var, 0.1, 1e-05);  conv2d_16 = p_layer4_0_bn2_weight = p_layer4_0_bn2_bias = b_layer4_0_bn2_running_mean = b_layer4_0_bn2_running_var = None\n",
       "                    getitem_48: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_17: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_12, p_layer4_0_downsample_0_weight, None, [2, 2]);  relu_12 = p_layer4_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_layer4_0_downsample_1_weight, p_layer4_0_downsample_1_bias, b_layer4_0_downsample_1_running_mean, b_layer4_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_17 = p_layer4_0_downsample_1_weight = p_layer4_0_downsample_1_bias = b_layer4_0_downsample_1_running_mean = b_layer4_0_downsample_1_running_var = None\n",
       "                    getitem_51: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_6: \"f32[1, 512, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_48, getitem_51);  getitem_48 = getitem_51 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_14: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(add_6);  add_6 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_18: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_14, p_layer4_1_conv1_weight, None, [1, 1], [1, 1]);  p_layer4_1_conv1_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_layer4_1_bn1_weight, p_layer4_1_bn1_bias, b_layer4_1_bn1_running_mean, b_layer4_1_bn1_running_var, 0.1, 1e-05);  conv2d_18 = p_layer4_1_bn1_weight = p_layer4_1_bn1_bias = b_layer4_1_bn1_running_mean = b_layer4_1_bn1_running_var = None\n",
       "                    getitem_54: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_15: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_19: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_15, p_layer4_1_conv2_weight, None, [1, 1], [1, 1]);  relu_15 = p_layer4_1_conv2_weight = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_layer4_1_bn2_weight, p_layer4_1_bn2_bias, b_layer4_1_bn2_running_mean, b_layer4_1_bn2_running_var, 0.1, 1e-05);  conv2d_19 = p_layer4_1_bn2_weight = p_layer4_1_bn2_bias = b_layer4_1_bn2_running_mean = b_layer4_1_bn2_running_var = None\n",
       "                    getitem_57: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:102 in forward, code: out += identity\n",
       "                    add_7: \"f32[1, 512, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_57, relu_14);  getitem_57 = relu_14 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_16: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(add_7);  add_7 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(relu_16, [-1, -2], True);  relu_16 = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285 in forward, code: return self._forward_impl(x)\n",
       "                    view: \"f32[1, 512]\" = torch.ops.aten.view.default(mean, [1, 512]);  mean = None\n",
       "            \n",
       "                     # File: d:\\Projects\\radya\\garbage-classification\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 10]\" = torch.ops.aten.linear.default(view, p_fc_weight, p_fc_bias);  view = p_fc_weight = p_fc_bias = None\n",
       "                    return (linear,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_conv1_weight: PARAMETER target='conv1.weight'\n",
       "            p_bn1_weight: PARAMETER target='bn1.weight'\n",
       "            p_bn1_bias: PARAMETER target='bn1.bias'\n",
       "            p_layer1_0_conv1_weight: PARAMETER target='layer1.0.conv1.weight'\n",
       "            p_layer1_0_bn1_weight: PARAMETER target='layer1.0.bn1.weight'\n",
       "            p_layer1_0_bn1_bias: PARAMETER target='layer1.0.bn1.bias'\n",
       "            p_layer1_0_conv2_weight: PARAMETER target='layer1.0.conv2.weight'\n",
       "            p_layer1_0_bn2_weight: PARAMETER target='layer1.0.bn2.weight'\n",
       "            p_layer1_0_bn2_bias: PARAMETER target='layer1.0.bn2.bias'\n",
       "            p_layer1_1_conv1_weight: PARAMETER target='layer1.1.conv1.weight'\n",
       "            p_layer1_1_bn1_weight: PARAMETER target='layer1.1.bn1.weight'\n",
       "            p_layer1_1_bn1_bias: PARAMETER target='layer1.1.bn1.bias'\n",
       "            p_layer1_1_conv2_weight: PARAMETER target='layer1.1.conv2.weight'\n",
       "            p_layer1_1_bn2_weight: PARAMETER target='layer1.1.bn2.weight'\n",
       "            p_layer1_1_bn2_bias: PARAMETER target='layer1.1.bn2.bias'\n",
       "            p_layer2_0_conv1_weight: PARAMETER target='layer2.0.conv1.weight'\n",
       "            p_layer2_0_bn1_weight: PARAMETER target='layer2.0.bn1.weight'\n",
       "            p_layer2_0_bn1_bias: PARAMETER target='layer2.0.bn1.bias'\n",
       "            p_layer2_0_conv2_weight: PARAMETER target='layer2.0.conv2.weight'\n",
       "            p_layer2_0_bn2_weight: PARAMETER target='layer2.0.bn2.weight'\n",
       "            p_layer2_0_bn2_bias: PARAMETER target='layer2.0.bn2.bias'\n",
       "            p_layer2_0_downsample_0_weight: PARAMETER target='layer2.0.downsample.0.weight'\n",
       "            p_layer2_0_downsample_1_weight: PARAMETER target='layer2.0.downsample.1.weight'\n",
       "            p_layer2_0_downsample_1_bias: PARAMETER target='layer2.0.downsample.1.bias'\n",
       "            p_layer2_1_conv1_weight: PARAMETER target='layer2.1.conv1.weight'\n",
       "            p_layer2_1_bn1_weight: PARAMETER target='layer2.1.bn1.weight'\n",
       "            p_layer2_1_bn1_bias: PARAMETER target='layer2.1.bn1.bias'\n",
       "            p_layer2_1_conv2_weight: PARAMETER target='layer2.1.conv2.weight'\n",
       "            p_layer2_1_bn2_weight: PARAMETER target='layer2.1.bn2.weight'\n",
       "            p_layer2_1_bn2_bias: PARAMETER target='layer2.1.bn2.bias'\n",
       "            p_layer3_0_conv1_weight: PARAMETER target='layer3.0.conv1.weight'\n",
       "            p_layer3_0_bn1_weight: PARAMETER target='layer3.0.bn1.weight'\n",
       "            p_layer3_0_bn1_bias: PARAMETER target='layer3.0.bn1.bias'\n",
       "            p_layer3_0_conv2_weight: PARAMETER target='layer3.0.conv2.weight'\n",
       "            p_layer3_0_bn2_weight: PARAMETER target='layer3.0.bn2.weight'\n",
       "            p_layer3_0_bn2_bias: PARAMETER target='layer3.0.bn2.bias'\n",
       "            p_layer3_0_downsample_0_weight: PARAMETER target='layer3.0.downsample.0.weight'\n",
       "            p_layer3_0_downsample_1_weight: PARAMETER target='layer3.0.downsample.1.weight'\n",
       "            p_layer3_0_downsample_1_bias: PARAMETER target='layer3.0.downsample.1.bias'\n",
       "            p_layer3_1_conv1_weight: PARAMETER target='layer3.1.conv1.weight'\n",
       "            p_layer3_1_bn1_weight: PARAMETER target='layer3.1.bn1.weight'\n",
       "            p_layer3_1_bn1_bias: PARAMETER target='layer3.1.bn1.bias'\n",
       "            p_layer3_1_conv2_weight: PARAMETER target='layer3.1.conv2.weight'\n",
       "            p_layer3_1_bn2_weight: PARAMETER target='layer3.1.bn2.weight'\n",
       "            p_layer3_1_bn2_bias: PARAMETER target='layer3.1.bn2.bias'\n",
       "            p_layer4_0_conv1_weight: PARAMETER target='layer4.0.conv1.weight'\n",
       "            p_layer4_0_bn1_weight: PARAMETER target='layer4.0.bn1.weight'\n",
       "            p_layer4_0_bn1_bias: PARAMETER target='layer4.0.bn1.bias'\n",
       "            p_layer4_0_conv2_weight: PARAMETER target='layer4.0.conv2.weight'\n",
       "            p_layer4_0_bn2_weight: PARAMETER target='layer4.0.bn2.weight'\n",
       "            p_layer4_0_bn2_bias: PARAMETER target='layer4.0.bn2.bias'\n",
       "            p_layer4_0_downsample_0_weight: PARAMETER target='layer4.0.downsample.0.weight'\n",
       "            p_layer4_0_downsample_1_weight: PARAMETER target='layer4.0.downsample.1.weight'\n",
       "            p_layer4_0_downsample_1_bias: PARAMETER target='layer4.0.downsample.1.bias'\n",
       "            p_layer4_1_conv1_weight: PARAMETER target='layer4.1.conv1.weight'\n",
       "            p_layer4_1_bn1_weight: PARAMETER target='layer4.1.bn1.weight'\n",
       "            p_layer4_1_bn1_bias: PARAMETER target='layer4.1.bn1.bias'\n",
       "            p_layer4_1_conv2_weight: PARAMETER target='layer4.1.conv2.weight'\n",
       "            p_layer4_1_bn2_weight: PARAMETER target='layer4.1.bn2.weight'\n",
       "            p_layer4_1_bn2_bias: PARAMETER target='layer4.1.bn2.bias'\n",
       "            p_fc_weight: PARAMETER target='fc.weight'\n",
       "            p_fc_bias: PARAMETER target='fc.bias'\n",
       "            b_bn1_running_mean: BUFFER target='bn1.running_mean' persistent=True\n",
       "            b_bn1_running_var: BUFFER target='bn1.running_var' persistent=True\n",
       "            b_bn1_num_batches_tracked: BUFFER target='bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_0_bn1_running_mean: BUFFER target='layer1.0.bn1.running_mean' persistent=True\n",
       "            b_layer1_0_bn1_running_var: BUFFER target='layer1.0.bn1.running_var' persistent=True\n",
       "            b_layer1_0_bn1_num_batches_tracked: BUFFER target='layer1.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_0_bn2_running_mean: BUFFER target='layer1.0.bn2.running_mean' persistent=True\n",
       "            b_layer1_0_bn2_running_var: BUFFER target='layer1.0.bn2.running_var' persistent=True\n",
       "            b_layer1_0_bn2_num_batches_tracked: BUFFER target='layer1.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer1_1_bn1_running_mean: BUFFER target='layer1.1.bn1.running_mean' persistent=True\n",
       "            b_layer1_1_bn1_running_var: BUFFER target='layer1.1.bn1.running_var' persistent=True\n",
       "            b_layer1_1_bn1_num_batches_tracked: BUFFER target='layer1.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer1_1_bn2_running_mean: BUFFER target='layer1.1.bn2.running_mean' persistent=True\n",
       "            b_layer1_1_bn2_running_var: BUFFER target='layer1.1.bn2.running_var' persistent=True\n",
       "            b_layer1_1_bn2_num_batches_tracked: BUFFER target='layer1.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_bn1_running_mean: BUFFER target='layer2.0.bn1.running_mean' persistent=True\n",
       "            b_layer2_0_bn1_running_var: BUFFER target='layer2.0.bn1.running_var' persistent=True\n",
       "            b_layer2_0_bn1_num_batches_tracked: BUFFER target='layer2.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_bn2_running_mean: BUFFER target='layer2.0.bn2.running_mean' persistent=True\n",
       "            b_layer2_0_bn2_running_var: BUFFER target='layer2.0.bn2.running_var' persistent=True\n",
       "            b_layer2_0_bn2_num_batches_tracked: BUFFER target='layer2.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer2_0_downsample_1_running_mean: BUFFER target='layer2.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer2_0_downsample_1_running_var: BUFFER target='layer2.0.downsample.1.running_var' persistent=True\n",
       "            b_layer2_0_downsample_1_num_batches_tracked: BUFFER target='layer2.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer2_1_bn1_running_mean: BUFFER target='layer2.1.bn1.running_mean' persistent=True\n",
       "            b_layer2_1_bn1_running_var: BUFFER target='layer2.1.bn1.running_var' persistent=True\n",
       "            b_layer2_1_bn1_num_batches_tracked: BUFFER target='layer2.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer2_1_bn2_running_mean: BUFFER target='layer2.1.bn2.running_mean' persistent=True\n",
       "            b_layer2_1_bn2_running_var: BUFFER target='layer2.1.bn2.running_var' persistent=True\n",
       "            b_layer2_1_bn2_num_batches_tracked: BUFFER target='layer2.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_bn1_running_mean: BUFFER target='layer3.0.bn1.running_mean' persistent=True\n",
       "            b_layer3_0_bn1_running_var: BUFFER target='layer3.0.bn1.running_var' persistent=True\n",
       "            b_layer3_0_bn1_num_batches_tracked: BUFFER target='layer3.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_bn2_running_mean: BUFFER target='layer3.0.bn2.running_mean' persistent=True\n",
       "            b_layer3_0_bn2_running_var: BUFFER target='layer3.0.bn2.running_var' persistent=True\n",
       "            b_layer3_0_bn2_num_batches_tracked: BUFFER target='layer3.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer3_0_downsample_1_running_mean: BUFFER target='layer3.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer3_0_downsample_1_running_var: BUFFER target='layer3.0.downsample.1.running_var' persistent=True\n",
       "            b_layer3_0_downsample_1_num_batches_tracked: BUFFER target='layer3.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer3_1_bn1_running_mean: BUFFER target='layer3.1.bn1.running_mean' persistent=True\n",
       "            b_layer3_1_bn1_running_var: BUFFER target='layer3.1.bn1.running_var' persistent=True\n",
       "            b_layer3_1_bn1_num_batches_tracked: BUFFER target='layer3.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer3_1_bn2_running_mean: BUFFER target='layer3.1.bn2.running_mean' persistent=True\n",
       "            b_layer3_1_bn2_running_var: BUFFER target='layer3.1.bn2.running_var' persistent=True\n",
       "            b_layer3_1_bn2_num_batches_tracked: BUFFER target='layer3.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer4_0_bn1_running_mean: BUFFER target='layer4.0.bn1.running_mean' persistent=True\n",
       "            b_layer4_0_bn1_running_var: BUFFER target='layer4.0.bn1.running_var' persistent=True\n",
       "            b_layer4_0_bn1_num_batches_tracked: BUFFER target='layer4.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer4_0_bn2_running_mean: BUFFER target='layer4.0.bn2.running_mean' persistent=True\n",
       "            b_layer4_0_bn2_running_var: BUFFER target='layer4.0.bn2.running_var' persistent=True\n",
       "            b_layer4_0_bn2_num_batches_tracked: BUFFER target='layer4.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_layer4_0_downsample_1_running_mean: BUFFER target='layer4.0.downsample.1.running_mean' persistent=True\n",
       "            b_layer4_0_downsample_1_running_var: BUFFER target='layer4.0.downsample.1.running_var' persistent=True\n",
       "            b_layer4_0_downsample_1_num_batches_tracked: BUFFER target='layer4.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_layer4_1_bn1_running_mean: BUFFER target='layer4.1.bn1.running_mean' persistent=True\n",
       "            b_layer4_1_bn1_running_var: BUFFER target='layer4.1.bn1.running_var' persistent=True\n",
       "            b_layer4_1_bn1_num_batches_tracked: BUFFER target='layer4.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_layer4_1_bn2_running_mean: BUFFER target='layer4.1.bn2.running_mean' persistent=True\n",
       "            b_layer4_1_bn2_running_var: BUFFER target='layer4.1.bn2.running_var' persistent=True\n",
       "            b_layer4_1_bn2_num_batches_tracked: BUFFER target='layer4.1.bn2.num_batches_tracked' persistent=True\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9221aa",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db48e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "model = resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "151ba7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_image(model, image_path, class_names):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "\n",
    "    results = {class_names[i]: float(probabilities[i]) for i in range(len(class_names))}\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dcd003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: battery (99.42%)\n",
      "battery: 99.42%\n",
      "biological: 0.00%\n",
      "cardboard: 0.00%\n",
      "clothes: 0.00%\n",
      "glass: 0.00%\n",
      "leafs: 0.00%\n",
      "metal: 0.00%\n",
      "paper: 0.58%\n",
      "plastic_bag: 0.00%\n",
      "plastic_bottle: 0.00%\n"
     ]
    }
   ],
   "source": [
    "class_names = full_dataset.classes\n",
    "result = predict_image(model, \"test/battery1.jpg\", class_names)\n",
    "\n",
    "top_class = max(result, key=result.get)\n",
    "print(f\"Predicted: {top_class} ({result[top_class]*100:.2f}%)\")\n",
    "\n",
    "for cls, prob in result.items():\n",
    "    print(f\"{cls}: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery1.jpg: predicted battery (99.42%) | true: battery | ✓\n",
      "biological1.jpg: predicted biological (100.00%) | true: biological | ✓\n",
      "cardboard1.jpg: predicted cardboard (95.86%) | true: cardboard | ✓\n",
      "clothes1.jpg: predicted clothes (78.99%) | true: clothes | ✓\n",
      "glass1.jpg: predicted glass (99.77%) | true: glass | ✓\n",
      "metal1.jpg: predicted metal (100.00%) | true: metal | ✓\n",
      "paper1.jpg: predicted biological (43.19%) | true: paper | ✗\n",
      "plastic1.jpg: predicted metal (59.98%) | true: plastic | ✗\n",
      "\n",
      "Accuracy: 75.00%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for filename in os.listdir(\"test\"):\n",
    "    if not filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(\"test\", filename)\n",
    "\n",
    "    # Extract label from filename (everything before the first digit)\n",
    "    true_label = ''.join([c for c in filename if not c.isdigit()]).split('.')[0]\n",
    "\n",
    "    result = predict_image(model, image_path, class_names)\n",
    "    predicted_label = max(result, key=result.get)\n",
    "\n",
    "    is_correct = predicted_label.lower() == true_label.lower()\n",
    "    total += 1\n",
    "    correct += int(is_correct)\n",
    "\n",
    "    print(f\"{filename}: predicted {predicted_label} ({result[predicted_label]*100:.2f}%) | true: {true_label} | {'✓' if is_correct else '✗'}\")\n",
    "\n",
    "accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
